"""
Station TV - Run Batch Whisper
Script principal de transcription batch multi-process.
Adapt√© depuis WhisperTranscriptor.py avec am√©liorations modulaires.

Usage:
    python scripts/RunBatchWhisper.py --config config/default_config.yaml
"""

import sys
import argparse
import yaml
import time
from pathlib import Path
from multiprocessing import Process
from typing import List

# Ajouter le r√©pertoire parent au path
sys.path.insert(0, str(Path(__file__).parent.parent))

from core.transcription import WhisperTranscriber
from core.affinity import CPUAffinityManager, Audio
from qos.monitor import SystemMonitor
from qos.metrics import MetricsCalculator
from qos.power_monitor import PowerMonitor
from qos.reporter import QoSReporter
from utils.logger import setup_logger
from utils.file_handler import FileHandler

# Logger
logger = setup_logger("RunBatchWhisper", level="INFO")


def load_config(config_file: str) -> dict:
    """Charge la configuration depuis un fichier YAML."""
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        logger.info(f"Configuration charg√©e depuis {config_file}")
        return config
    except Exception as e:
        logger.error(f"Erreur lors du chargement de la configuration: {str(e)}")
        sys.exit(1)


def process_audio_files_on_core(
    audio_list: List[Audio],
    config: dict,
    cpu_cores: List[int],
    core_index: int,
    metrics_calculator: MetricsCalculator
):
    """
    Lance s√©quentiellement la transcription sur chaque fichier Audio de la liste.
    Adapt√© depuis WhisperTranscriptor.py
    
    Args:
        audio_list: Liste d'objets Audio √† traiter
        config: Configuration
        cpu_cores: Liste des c≈ìurs CPU √† utiliser
        core_index: Index du processus
        metrics_calculator: Calculateur de m√©triques
    """
    duree_totale = sum(audio.duree for audio in audio_list)
    logger.info(
        f"Processus {core_index}: {len(audio_list)} fichiers, "
        f"dur√©e totale: {duree_totale:.2f}s ({duree_totale/3600:.2f}h)"
    )
    
    # Cr√©er le r√©pertoire trackers
    trackers_dir = Path(config.get('paths', {}).get('trackers_dir', 'trackers'))
    trackers_dir.mkdir(exist_ok=True)
    tracker_path = trackers_dir / f"Tracker{core_index}.txt"
    
    # R√©initialiser le tracker
    with open(tracker_path, 'w', encoding='utf-8') as f:
        f.write(f"=== Processus {core_index} - {len(audio_list)} fichiers ===\n\n")
    
    # Cr√©er le transcripteur
    transcriber = WhisperTranscriber(config)
    
    # Traiter chaque fichier
    for i, audio in enumerate(audio_list, 1):
        try:
            filename = Path(audio.path).name
            
            # Log de d√©but de traitement
            logger.info("")
            logger.info("=" * 80)
            logger.info(f"PROCESSUS {core_index} | Fichier {i}/{len(audio_list)} | Progression: {i/len(audio_list)*100:.1f}%")
            logger.info("=" * 80)
            logger.info(f"Fichier   : {filename}")
            logger.info(f"Dur√©e     : {audio.duree / 60:.2f} min ({audio.duree:.0f}s)")
            logger.info(f"Chemin    : {audio.path}")
            logger.info("-" * 80)
            logger.info("D√©marrage de la transcription...")
            
            start_time = time.time()
            
            # Transcription
            success = transcriber.process_and_write(
                audio.path,
                cpu_cores,
                core_index,
                str(tracker_path)
            )
            
            processing_time = time.time() - start_time
            throughput = audio.duree / processing_time if processing_time > 0 else 0
            
            # Ajouter aux m√©triques
            if metrics_calculator:
                metrics_calculator.add_transcription(
                    audio_duration=audio.duree,
                    processing_time=processing_time,
                    file_path=audio.path,
                    model=config.get('whisper', {}).get('model', 'unknown'),
                    success=success
                )
            
            # Log de fin de traitement
            if success:
                logger.info("-" * 80)
                logger.info(f"[SUCCES] Processus {core_index} | {filename}")
                logger.info(f"   Temps traitement : {processing_time:.2f}s")
                logger.info(f"   Throughput       : {throughput:.2f}x temps r√©el")
                logger.info(f"   Restant          : {len(audio_list) - i} fichiers")
                logger.info("=" * 80)
            else:
                logger.error("-" * 80)
                logger.error(f"[ECHEC] Processus {core_index} | {filename}")
                logger.error("=" * 80)
                
        except Exception as e:
            logger.error(f"Erreur lors du traitement de {audio.path}: {str(e)}")


def lancer_traitement_batch(config: dict, metrics_calculator: MetricsCalculator):
    """
    Lance les processus de traitement batch.
    Adapt√© depuis WhisperTranscriptor.py
    
    Args:
        config: Configuration
        metrics_calculator: Calculateur de m√©triques
    """
    # Charger les fichiers audio depuis le CSV
    csv_path = config.get('paths', {}).get('csv_filename', 'fichiers_audio.csv')
    
    if not Path(csv_path).exists():
        logger.error(f"Fichier CSV introuvable: {csv_path}")
        return []
    
    logger.info(f"Chargement des fichiers audio depuis {csv_path}...")
    
    # Lire le CSV
    donnees = FileHandler.lire_csv(csv_path)
    
    if not donnees:
        logger.error("Aucun fichier audio trouv√© dans le CSV")
        return []
    
    # Convertir en objets Audio
    liste_audios = [Audio(path, duree) for path, duree in donnees]
    logger.info(f"{len(liste_audios)} fichiers audio charg√©s")
    
    # Nombre de processus
    nb_processus = config.get('hardware', {}).get('max_parallel_processes', 3)
    logger.info(f"Nombre de processus parall√®les: {nb_processus}")
    
    # Limite de fichiers par processus
    max_files_per_process = config.get('batch', {}).get('max_files_per_process', 0)
    if max_files_per_process > 0:
        logger.info(f"Limite de fichiers par processus: {max_files_per_process}")
    else:
        logger.info("Fichiers par processus: illimit√©")
    
    # Regrouper les fichiers par dossier parent (Coeur1, Coeur2, ...)
    import re
    fichiers_par_dossier = {}
    for audio in liste_audios:
        dossier_parent = Path(audio.path).parent.name
        if dossier_parent not in fichiers_par_dossier:
            fichiers_par_dossier[dossier_parent] = []
        fichiers_par_dossier[dossier_parent].append(audio)
    
    # D√©tecter le mode "dossiers Coeur"
    noms_dossiers = list(fichiers_par_dossier.keys())
    mode_coeur = any("coeur" in d.lower() for d in noms_dossiers) and len(noms_dossiers) > 1
    
    if mode_coeur:
        # Tri naturel (Coeur1, Coeur2, ..., Coeur10, ..., Coeur30)
        def natural_sort_key(s):
            return [int(t) if t.isdigit() else t.lower() for t in re.split(r'(\d+)', s)]
        
        dossiers_tries = sorted(noms_dossiers, key=natural_sort_key)
        
        # Limiter au nombre de processus configur√©
        if len(dossiers_tries) > nb_processus:
            logger.warning(
                f"{len(dossiers_tries)} dossiers Coeur trouv√©s mais max_parallel_processes={nb_processus}. "
                f"Seuls Coeur1 √† Coeur{nb_processus} seront trait√©s."
            )
            dossiers_tries = dossiers_tries[:nb_processus]
        
        logger.info(f"Mode 'Coeurs' d√©tect√© : {len(dossiers_tries)} dossiers -> {len(dossiers_tries)} processus")
        
        listes_audio = []
        for i, nom_dossier in enumerate(dossiers_tries):
            fichiers = fichiers_par_dossier[nom_dossier]
            # Appliquer la limite max_files_per_process
            if max_files_per_process > 0 and len(fichiers) > max_files_per_process:
                logger.info(f"  {nom_dossier}: {len(fichiers)} fichiers trouv√©s, limit√© √† {max_files_per_process}")
                fichiers = fichiers[:max_files_per_process]
            duree_totale = sum(a.duree for a in fichiers) / 3600
            logger.info(f"  Processus {i+1} -> {nom_dossier} ({len(fichiers)} fichiers, {duree_totale:.1f}h)")
            listes_audio.append(fichiers)
    else:
        # R√©partition classique avec algorithme glouton
        logger.info("Mode classique : √©quilibrage de charge par dur√©e")
        listes_audio = CPUAffinityManager.equilibrage_charge(liste_audios, nb_processus, max_per_list=max_files_per_process)
    
    # Configuration des c≈ìurs CPU
    cpu_affinity = config.get('whisper', {}).get('cpu_affinity', [])
    
    if len(cpu_affinity) < nb_processus:
        logger.warning(
            f"Configuration CPU insuffisante ({len(cpu_affinity)} configs pour "
            f"{nb_processus} processus). Utilisation par d√©faut."
        )
        # R√©partition automatique
        cores_per_process = config.get('hardware', {}).get('cpu_threads', 36) // nb_processus
        cpu_affinity = [
            list(range(i * cores_per_process, (i + 1) * cores_per_process))
            for i in range(nb_processus)
        ]
    
    # Lancer les processus
    processes = []
    for i, liste_audio in enumerate(listes_audio):
        if not liste_audio:
            logger.warning(f"Liste {i+1} vide, processus non lanc√©")
            continue
        
        logger.info(f"Lancement du processus {i+1} sur les c≈ìurs {cpu_affinity[i]}")
        
        p = Process(
            target=process_audio_files_on_core,
            args=(liste_audio, config, cpu_affinity[i], i+1, metrics_calculator)
        )
        p.start()
        processes.append(p)
    
    return processes


def main():
    """Fonction principale."""
    parser = argparse.ArgumentParser(
        description="Transcription batch multi-process - Station TV"
    )
    parser.add_argument(
        '--config', '-c',
        default='config/default_config.yaml',
        help="Fichier de configuration YAML (d√©faut: config/default_config.yaml)"
    )
    parser.add_argument(
        '--scan-only',
        action='store_true',
        help="Scanner les fichiers audio sans lancer la transcription"
    )
    
    args = parser.parse_args()
    
    # Charger la configuration
    config = load_config(args.config)
    
    logger.info("=" * 80)
    logger.info("STATION TV - TRANSCRIPTION AUDIO HAUTE PERFORMANCE")
    logger.info("=" * 80)
    
    # √âtape 1: Scanner les fichiers audio
    logger.info("\n" + "=" * 80)
    logger.info("√âTAPE 1: ANALYSE DES FICHIERS AUDIO")
    logger.info("=" * 80)
    
    input_dir = config.get('paths', {}).get('input_audio_dir', 'bdd')
    suffixes = ['.mp3', '.wav']
    
    logger.info(f"R√©pertoire d'entr√©e: {input_dir}")
    logger.info(f"Extensions recherch√©es: {suffixes}")
    
    # Scanner les fichiers
    fichiers_audio = FileHandler.lister_fichiers(input_dir, suffixes)
    
    if not fichiers_audio:
        logger.error("Aucun fichier audio trouv√©!")
        return
    
    logger.info(f"\n{len(fichiers_audio)} fichiers audio trouv√©s")
    logger.info("\nLISTE DES FICHIERS DETECTES:")
    logger.info("-" * 80)
    
    # Afficher la liste des fichiers avec leur dur√©e
    total_duration = 0
    for i, fichier in enumerate(fichiers_audio, 1):
        filename = Path(fichier.chemin).name
        duration_min = fichier.longueur / 60
        total_duration += fichier.longueur
        logger.info(f"  {i:3d}. {filename:60s} ({duration_min:6.2f} min)")
    
    total_hours = total_duration / 3600
    logger.info("-" * 80)
    logger.info(f"Dur√©e audio totale : {total_hours:.2f} heures ({total_duration:.0f} secondes)")
    logger.info("-" * 80)
    
    # √âcrire le CSV
    csv_path = config.get('paths', {}).get('csv_filename', 'fichiers_audio.csv')
    FileHandler.ecrire_csv(fichiers_audio, csv_path)
    logger.info(f"\nFichier CSV cr√©√©: {csv_path}")
    
    if args.scan_only:
        logger.info("Mode scan-only: arr√™t apr√®s le scan des fichiers")
        return
    
    # √âtape 2: Transcription batch
    logger.info("\n" + "=" * 80)
    logger.info("√âTAPE 2: TRANSCRIPTION BATCH")
    logger.info("=" * 80)
    
    # Cr√©er le calculateur de m√©triques
    metrics_calculator = MetricsCalculator()
    metrics_calculator.start_session()
    
    # D√©marrer le monitoring syst√®me (si activ√©)
    qos_enabled = config.get('qos', {}).get('enabled', True)
    monitor = None
    power_monitor = None
    
    if qos_enabled:
        logger.info("\n" + "-" * 80)
        logger.info("D√©marrage du monitoring QoS...")
        logger.info("-" * 80)
        
        output_dir = config.get('paths', {}).get('reports_dir', 'output/reports')
        interval = config.get('qos', {}).get('monitoring_interval', 2)
        
        monitor = SystemMonitor(output_dir=output_dir, interval=interval)
        monitor.start()
        
        # D√©marrer le monitoring √©nerg√©tique
        power_config = config.get('qos', {}).get('power', {})
        if power_config.get('enabled', True):
            logger.info("D√©marrage du monitoring √©nerg√©tique...")
            power_monitor = PowerMonitor(
                output_dir=output_dir,
                interval=interval,
                tdp_watts=power_config.get('tdp_watts'),
                electricity_cost_per_kwh=power_config.get('cost_per_kwh', 0.18),
                carbon_intensity=power_config.get('carbon_kg_per_kwh', 0.1)
            )
            power_monitor.start()
    
    try:
        # Lancer le traitement batch
        processes = lancer_traitement_batch(config, metrics_calculator)
        
        if not processes:
            logger.error("Aucun processus lanc√©")
            return
        
        logger.info(f"\n{len(processes)} processus lanc√©s, attente de la fin...")
        
        # Attendre la fin de tous les processus
        for p in processes:
            p.join()
        
        # Terminer la session de m√©triques
        metrics_calculator.end_session()
        
        logger.info("\n" + "=" * 80)
        logger.info("TRAITEMENT TERMIN√â AVEC SUCC√àS")
        logger.info("=" * 80)
        
        # Afficher le r√©sum√© des m√©triques
        summary = metrics_calculator.get_summary()
        
        logger.info("\nR√âSUM√â DES PERFORMANCES:")
        logger.info("-" * 80)
        logger.info(f"Fichiers trait√©s: {summary['successful_files']}/{summary['total_files']}")
        logger.info(f"Taux de r√©ussite: {summary['success_rate']*100:.1f}%")
        logger.info(f"Dur√©e totale: {summary['session_duration_hours']:.2f}h")
        logger.info(f"Audio trait√©: {summary['total_audio_duration_hours']:.2f}h")
        logger.info(f"Throughput: {summary['throughput']:.2f}√ó temps r√©el")
        logger.info("-" * 80)
        
        # G√©n√©rer les graphiques et rapports (si activ√© dans la config)
        if qos_enabled and config.get('qos', {}).get('generate_graphs', True):
            logger.info("\n" + "=" * 80)
            logger.info("G√âN√âRATION DES RAPPORTS ET GRAPHIQUES")
            logger.info("=" * 80)
            
            output_dir = config.get('paths', {}).get('reports_dir', 'output/reports')
            reporter = QoSReporter(output_dir=output_dir)
            
            # Graphique CPU
            cpu_file = Path(output_dir) / "monitoring_cpu.csv"
            if cpu_file.exists():
                logger.info("\nG√©n√©ration du graphique CPU...")
                if reporter.plot_cpu_usage(str(cpu_file)):
                    logger.info("‚úì Graphique CPU g√©n√©r√©")
                else:
                    logger.warning("‚ö† √âchec g√©n√©ration graphique CPU")
            
            # Graphique RAM
            memory_file = Path(output_dir) / "monitoring_memory.csv"
            if memory_file.exists():
                logger.info("\nG√©n√©ration du graphique RAM...")
                if reporter.plot_memory_usage(str(memory_file)):
                    logger.info("‚úì Graphique RAM g√©n√©r√©")
                else:
                    logger.warning("‚ö† √âchec g√©n√©ration graphique RAM")
            
            # Graphique I/O
            io_file = Path(output_dir) / "monitoring_io.csv"
            if io_file.exists():
                logger.info("\nG√©n√©ration du graphique I/O...")
                if reporter.plot_io_usage(str(io_file)):
                    logger.info("‚úì Graphique I/O g√©n√©r√©")
                else:
                    logger.warning("‚ö† √âchec g√©n√©ration graphique I/O")
            
            # Graphique de consommation √©nerg√©tique
            power_file = Path(output_dir) / "monitoring_power.csv"
            if power_file.exists() and config.get('qos', {}).get('power', {}).get('enabled', True):
                logger.info("\nG√©n√©ration du graphique de consommation √©nerg√©tique...")
                power_graph = reporter.plot_power_usage(str(power_file))
                if power_graph:
                    logger.info("‚úì Graphique √©nerg√©tique g√©n√©r√©")
                else:
                    logger.warning("‚ö† √âchec g√©n√©ration graphique √©nerg√©tique")
            
            # Rapport de synth√®se
            if config.get('qos', {}).get('export_csv', True):
                logger.info("\nG√©n√©ration du rapport de synth√®se...")
                if reporter.generate_summary_report(summary):
                    logger.info("‚úì Rapport de synth√®se g√©n√©r√©")
                else:
                    logger.warning("‚ö† √âchec g√©n√©ration rapport")
            
            logger.info("\n" + "=" * 80)
            logger.info(f"üìä Tous les rapports sont disponibles dans: {output_dir}")
            logger.info("=" * 80)
        
    except KeyboardInterrupt:
        logger.warning("\n‚ö†Ô∏è Interruption par l'utilisateur")
    except Exception as e:
        logger.error(f"\n‚ùå Erreur: {str(e)}")
    finally:
        # Arr√™ter le monitoring
        if monitor:
            logger.info("\nArr√™t du monitoring QoS...")
            monitor.stop()
            logger.info("‚úì Monitoring arr√™t√©")
        
        # Arr√™ter le monitoring √©nerg√©tique
        if power_monitor:
            logger.info("\nArr√™t du monitoring √©nerg√©tique...")
            power_summary = power_monitor.stop()
            logger.info("‚úì Monitoring √©nerg√©tique arr√™t√©")


if __name__ == "__main__":
    main()
