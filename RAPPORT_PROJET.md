# Station TV â€” Rapport de Projet

## 1. PrÃ©sentation GÃ©nÃ©rale

### 1.1 Contexte et Objectifs

**Station TV** est un systÃ¨me de transcription automatique d'enregistrements audio issus de la TNT franÃ§aise. Le projet vise Ã  convertir massivement des fichiers audio (MP3, WAV) en texte Ã  l'aide du modÃ¨le de reconnaissance vocale **Whisper** (d'OpenAI), tout en maximisant les performances grÃ¢ce Ã  un traitement parallÃ¨le multi-processus.

Le systÃ¨me est conÃ§u pour fonctionner sur un serveur **Dell Precision 5820** Ã©quipÃ© de :
- **CPU** : Intel Xeon W-2295 (18 cÅ“urs physiques, 36 threads)
- **RAM** : 256 Go DDR4
- **OS** : Windows (chemins configurÃ©s en consÃ©quence)

### 1.2 Objectifs Principaux

| Objectif | Description |
|---|---|
| **Transcription massive** | Transcrire ~720 heures d'audio (24 fichiers Ã— 1h Ã— 30 processus) en quelques heures |
| **Haute performance** | Exploitation de 30 processus parallÃ¨les avec affinitÃ© CPU par cÅ“ur |
| **Supervision complÃ¨te** | Monitoring temps rÃ©el du CPU, RAM, I/O disque et consommation Ã©nergÃ©tique |
| **QualitÃ© contrÃ´lÃ©e** | MÃ©triques QoS (throughput, WER, taux de rÃ©ussite, temps de traitement) |
| **Formats multiples** | Sortie en TXT (texte brut), SRT (sous-titres horodatÃ©s), CSV et JSON |

### 1.3 Moteur de Transcription

Le projet utilise **faster-whisper**, une implÃ©mentation optimisÃ©e de Whisper basÃ©e sur **CTranslate2** au lieu de PyTorch. Ce choix permet :
- **~3-4Ã— plus rapide** que openai-whisper (PyTorch)
- **~70-80% de RAM en moins** par processus (quantification int8)
- QualitÃ© de transcription quasi-identique

---

## 2. Architecture du Projet

### 2.1 Vue d'Ensemble

```
stationtv/
â”œâ”€â”€ core/                    # Modules mÃ©tier principaux
â”‚   â”œâ”€â”€ models.py            # Gestion des modÃ¨les Whisper (chargement, cache, RAM)
â”‚   â”œâ”€â”€ transcription.py     # Moteur de transcription (faster-whisper)
â”‚   â””â”€â”€ affinity.py          # AffinitÃ© CPU et rÃ©partition de charge
â”‚
â”œâ”€â”€ qos/                     # Supervision et qualitÃ© de service
â”‚   â”œâ”€â”€ monitor.py           # Monitoring temps rÃ©el (CPU, RAM, I/O)
â”‚   â”œâ”€â”€ metrics.py           # Calcul des mÃ©triques (throughput, WER, succÃ¨s)
â”‚   â”œâ”€â”€ power_monitor.py     # Monitoring Ã©nergÃ©tique (RAPL / estimation)
â”‚   â””â”€â”€ reporter.py          # GÃ©nÃ©ration de graphiques et rapports PNG
â”‚
â”œâ”€â”€ preprocessing/           # PrÃ©traitement audio
â”‚   â””â”€â”€ audio_converter.py   # Conversion MP3 â†’ WAV via FFmpeg
â”‚
â”œâ”€â”€ export/                  # Export des rÃ©sultats
â”‚   â””â”€â”€ exporter.py          # Export JSON, CSV et backup
â”‚
â”œâ”€â”€ utils/                   # Utilitaires transversaux
â”‚   â”œâ”€â”€ file_handler.py      # Scan rÃ©cursif de fichiers, mÃ©tadonnÃ©es audio
â”‚   â””â”€â”€ logger.py            # SystÃ¨me de logging centralisÃ©
â”‚
â”œâ”€â”€ scripts/                 # Points d'entrÃ©e exÃ©cutables
â”‚   â”œâ”€â”€ RunBatchWhisper.py   # Script principal: transcription batch multi-process
â”‚   â”œâ”€â”€ RunPipeline.py       # Pipeline automatique complet (scan â†’ transcription â†’ QoS)
â”‚   â”œâ”€â”€ BenchmarkModels.py   # Benchmark comparatif des modÃ¨les (tiny â†’ large)
â”‚   â”œâ”€â”€ BasicTestWhisper.py  # Test rapide de transcription sur un fichier
â”‚   â”œâ”€â”€ ComputeQoS.py        # GÃ©nÃ©ration post-traitement des rapports QoS
â”‚   â”œâ”€â”€ CompareTranscriptions.py  # Comparaison Small vs Medium (WER + diff HTML)
â”‚   â”œâ”€â”€ GenerateExcelReport.py    # Rapport Excel formatÃ© avec graphiques
â”‚   â”œâ”€â”€ PrepareTestFiles.py       # PrÃ©paration des fichiers de test
â”‚   â”œâ”€â”€ CheckBenchmarkSetup.py    # VÃ©rification de l'environnement benchmark
â”‚   â””â”€â”€ RunTests.py               # Lanceur de tests unitaires
â”‚
â”œâ”€â”€ tests/                   # Tests unitaires
â”‚   â””â”€â”€ test_core.py         # Tests ModelManager, CPUAffinity, Metrics, FileHandler
â”‚
â”œâ”€â”€ config/                  # Configuration
â”‚   â”œâ”€â”€ default_config.yaml  # Configuration principale (matÃ©riel, Whisper, QoS, paths)
â”‚   â”œâ”€â”€ benchmark_config.yaml # Configuration spÃ©cifique aux benchmarks
â”‚   â””â”€â”€ MONITORING_CONFIG.md  # Documentation de la configuration monitoring
â”‚
â”œâ”€â”€ docs/                    # Documentation
â”‚   â”œâ”€â”€ BENCHMARK_GUIDE.md
â”‚   â”œâ”€â”€ BENCHMARK_QUICKSTART.md
â”‚   â”œâ”€â”€ POWER_MONITORING.md
â”‚   â””â”€â”€ STVD_NAMING_CONVENTION.md
â”‚
â”œâ”€â”€ diagrams/                # Diagrammes UML (PlantUML)
â”‚   â”œâ”€â”€ class_diagram.puml
â”‚   â”œâ”€â”€ sequence_batch_transcription.puml
â”‚   â””â”€â”€ sequence_simple_transcription.puml
â”‚
â”œâ”€â”€ requirements.txt         # DÃ©pendances Python
â”œâ”€â”€ RUN_PIPELINE.bat         # Lanceur Windows
â”œâ”€â”€ README.md
â”œâ”€â”€ QUICKSTART.md
â””â”€â”€ SPECIFICATIONS_TECHNIQUES.md
```

### 2.2 Diagramme de DÃ©pendances

```mermaid
graph TD
    RBW["RunBatchWhisper.py<br/><i>Script principal</i>"] --> WT["WhisperTranscriber<br/><i>core/transcription.py</i>"]
    RBW --> SM["SystemMonitor<br/><i>qos/monitor.py</i>"]
    RBW --> MC["MetricsCalculator<br/><i>qos/metrics.py</i>"]
    RBW --> PM["PowerMonitor<br/><i>qos/power_monitor.py</i>"]
    RBW --> QR["QoSReporter<br/><i>qos/reporter.py</i>"]
    RBW --> FH["FileHandler<br/><i>utils/file_handler.py</i>"]
    RBW --> CA["CPUAffinityManager<br/><i>core/affinity.py</i>"]
    
    WT --> MM["ModelManager<br/><i>core/models.py</i>"]
    WT --> CA
    
    MM --> FW["faster-whisper<br/><i>CTranslate2</i>"]
    
    BM["BenchmarkModels.py"] --> WT
    RP["RunPipeline.py"] --> RBW
    CT["CompareTranscriptions.py"] --> MC
    CQ["ComputeQoS.py"] --> QR
    
    style FW fill:#4CAF50,color:white
    style RBW fill:#2196F3,color:white
    style WT fill:#FF9800,color:white
    style MM fill:#FF9800,color:white
```

---

## 3. Modules en DÃ©tail

### 3.1 Core â€” `core/`

#### 3.1.1 `models.py` â€” ModelManager

Gestionnaire centralisÃ© des modÃ¨les Whisper utilisant **faster-whisper** (CTranslate2).

**ResponsabilitÃ©s :**
- Chargement et mise en cache des modÃ¨les (`WhisperModel`)
- Validation de la disponibilitÃ© mÃ©moire avant lancement
- Estimation de la RAM nÃ©cessaire par configuration

**ModÃ¨les supportÃ©s :**

| ModÃ¨le | RAM estimÃ©e (int8) | Suffixe fichier | QualitÃ© |
|---|---|---|---|
| `tiny` | 0.5 Go | `wt` | Basique |
| `base` | 0.5 Go | `wb` | Acceptable |
| `small` | 1 Go | `ws` | Bonne |
| `medium` | 3 Go | `wm` | TrÃ¨s bonne |
| `large` / `large-v2` / `large-v3` | 5 Go | `wl` / `wl2` / `wl3` | Excellente |

**ParamÃ¨tres clÃ©s :**
- `device` : `cpu` ou `cuda` (CPU par dÃ©faut pour stabilitÃ©)
- `compute_type` : `int8` (quantification optimale pour CPU), `float16`, `float32`

**API principale :**
```python
manager = ModelManager(device="cpu", compute_type="int8")
model = manager.load_model("medium")          # Charge et met en cache
ram = manager.estimate_ram_usage("medium", 30) # Estime RAM pour 30 processus
manager.validate_memory_availability("medium", 30, total_ram_gb=256)
```

---

#### 3.1.2 `transcription.py` â€” WhisperTranscriber

Moteur de transcription principal. Orchestre le chargement du modÃ¨le, l'exÃ©cution de la transcription et l'Ã©criture des fichiers de sortie.

**ResponsabilitÃ©s :**
- Transcription audio â†’ texte via faster-whisper
- DÃ©finition de l'affinitÃ© CPU par processus
- GÃ©nÃ©ration des fichiers TXT et SRT
- Conversion du rÃ©sultat faster-whisper (gÃ©nÃ©rateur) en dict compatible

**Flux de transcription :**

```mermaid
sequenceDiagram
    participant S as Script (RunBatch)
    participant T as WhisperTranscriber
    participant M as ModelManager
    participant FW as faster-whisper
    participant FS as Fichiers sortie

    S->>T: process_and_write(audio, cores)
    T->>T: set_cpu_affinity(cores)
    T->>M: load_model("medium")
    M-->>T: WhisperModel (cachÃ©)
    T->>FW: model.transcribe(audio)
    FW-->>T: (segments_generator, info)
    T->>T: Convertir segments â†’ dict
    T->>FS: create_txt_file(result)
    T->>FS: create_srt_file(segments)
    T-->>S: success = True
```

**Format de sortie normalisÃ© :**
```python
result = {
    "text": "Transcription complÃ¨te...",
    "segments": [
        {"id": 0, "start": 0.0, "end": 2.5, "text": "Bonjour", "words": [...]},
        ...
    ],
    "language": "fr",
    "duration": 3600.0
}
```

**Convention de nommage des fichiers (STVD-MNER) :**
- TXT : `{timestamp}_transcript_{model_suffix}.txt`
- SRT : `{timestamp}_transcript_st_{model_suffix}.srt`

---

#### 3.1.3 `affinity.py` â€” CPUAffinityManager

Gestion de l'affinitÃ© CPU et rÃ©partition Ã©quilibrÃ©e de la charge audio entre processus.

**ResponsabilitÃ©s :**
- Ã‰pinglage des processus sur des cÅ“urs CPU spÃ©cifiques via `psutil`
- Algorithme glouton pour rÃ©partir N fichiers audio sur K processus de maniÃ¨re Ã©quilibrÃ©e

**Algorithme glouton (`glouton_n_listes`) :**
1. Trier les fichiers audio par durÃ©e dÃ©croissante
2. Pour chaque fichier, l'affecter au processus ayant la charge totale la plus faible
3. RÃ©sultat : des listes de durÃ©es quasi-Ã©gales â†’ temps de fin homogÃ¨ne entre processus

```python
audios = [Audio("f1.mp3", 3600), Audio("f2.mp3", 1800), ...]
listes = CPUAffinityManager.glouton_n_listes(audios, n=30)
# â†’ 30 listes Ã©quilibrÃ©es
```

---

### 3.2 QoS â€” `qos/`

#### 3.2.1 `monitor.py` â€” SystemMonitor

Monitoring systÃ¨me temps rÃ©el avec threads en arriÃ¨re-plan. Enregistre les donnÃ©es dans des fichiers CSV.

**MÃ©triques surveillÃ©es :**

| MÃ©trique | Fichier CSV | Colonnes |
|---|---|---|
| CPU | `monitoring_cpu.csv` | Timestamp, CPU_Usage_Percent |
| RAM | `monitoring_memory.csv` | Timestamp, Memory_Percent, Memory_Used_GB, Memory_Total_GB |
| I/O disque | `monitoring_io.csv` | Timestamp, IO_Usage_Percent, Read_MB_s, Write_MB_s, Read_IOPS, Write_IOPS |

**Usage :**
```python
monitor = SystemMonitor(output_dir="reports", interval=10)
monitor.start()    # Lance 3 threads daemon (CPU, RAM, I/O)
# ... transcription en cours ...
monitor.stop()     # ArrÃªte et joint les threads
```

Supporte le context manager (`with SystemMonitor(...) as m:`).

---

#### 3.2.2 `metrics.py` â€” MetricsCalculator

Calcul des mÃ©triques de qualitÃ© de service de la transcription.

**MÃ©triques calculÃ©es :**

| MÃ©trique | Description | Formule |
|---|---|---|
| **Throughput** | DÃ©bit de transcription | `durÃ©e_audio_totale / temps_rÃ©el_total` |
| **Taux de rÃ©ussite** | % de transcriptions rÃ©ussies | `succÃ¨s / total` |
| **Temps moyen** | Temps de traitement par fichier | `Î£ temps / N` |
| **WER** | Word Error Rate (distance d'Ã©dition) | `(Sub + Ins + Del) / Nombre_mots_ref` |

Le WER est implÃ©mentÃ© via l'algorithme de **Levenshtein** (programmation dynamique) :
- Substitutions, insertions et suppressions de mots
- Score de 0.0 (parfait) Ã  1.0+ (complÃ¨tement faux)

---

#### 3.2.3 `power_monitor.py` â€” PowerMonitor

Monitoring de la consommation Ã©nergÃ©tique du serveur.

**MÃ©thodes de mesure :**
1. **Intel RAPL** (si disponible via `pyRAPL`) : lecture directe des registres MSR du processeur
2. **Estimation CPU** (fallback) : `puissance = TDP Ã— (utilisation_CPU / 100)`

**MÃ©triques calculÃ©es :**
- Puissance instantanÃ©e (Watts)
- Ã‰nergie totale consommÃ©e (kWh)
- CoÃ»t financier estimÃ© (â‚¬, basÃ© sur 0.18 â‚¬/kWh â€” moyenne France)
- Ã‰missions COâ‚‚ estimÃ©es (kg, basÃ© sur 0.1 kg COâ‚‚/kWh â€” mix France)

---

#### 3.2.4 `reporter.py` â€” QoSReporter

GÃ©nÃ©ration de graphiques et rapports visuels Ã  partir des fichiers CSV de monitoring.

**Graphiques gÃ©nÃ©rÃ©s :**

| Graphique | Fichier PNG | Contenu |
|---|---|---|
| CPU | `cpu_usage.png` | Courbe d'utilisation CPU (%) avec moyenne |
| RAM | `memory_usage.png` | 2 subplots : % utilisation + Go utilisÃ©s/totaux |
| Ã‰nergie | `power_usage.png` | Puissance (W) et Ã©nergie cumulative (Wh) |
| I/O | `io_usage.png` | 2 subplots : % occupation disque + dÃ©bit R/W (MB/s) |

Utilise `matplotlib` + `seaborn` pour un rendu professionnel.

---

### 3.3 Preprocessing â€” `preprocessing/`

#### `audio_converter.py` â€” AudioConverter

Conversion de fichiers audio via **FFmpeg**.

**Configuration par dÃ©faut :**
- Format cible : WAV
- FrÃ©quence : 48 000 Hz
- Canaux : 1 (mono)
- Profondeur : 16 bits (PCM16)

Supporte la conversion unitaire (`convert_to_wav`) et par lot (`convert_batch`).

---

### 3.4 Export â€” `export/`

#### `exporter.py` â€” TranscriptionExporter

Export des rÃ©sultats de transcription dans des formats structurÃ©s.

**Formats d'export :**
- **JSON** : structure complÃ¨te avec mÃ©tadonnÃ©es (version, timestamp, segments horodatÃ©s)
- **CSV** : tableau tabulaire avec chemin, durÃ©e, texte, nombre de segments, mÃ©tadonnÃ©es (chaÃ®ne, date, Ã©mission)
- **Backup** : copie ou archive ZIP des transcriptions avec timestamp

---

### 3.5 Utils â€” `utils/`

#### `file_handler.py` â€” FileHandler

Scan rÃ©cursif de fichiers audio dans une arborescence de rÃ©pertoires.

**FonctionnalitÃ©s :**
- `lister_fichiers(chemin, suffixes)` : parcours rÃ©cursif (pile), filtre par extension, extrait la durÃ©e via `mutagen`
- `ecrire_csv(objets, fichier)` : export de l'inventaire (chemin, durÃ©e) en CSV
- `lire_csv(fichier)` : lecture d'un inventaire CSV existant
- Filtrage automatique des fichiers sans piste audio dÃ©tectable (durÃ©e = 0)

#### `logger.py`

SystÃ¨me de logging centralisÃ© avec formatage standardisÃ© (`asctime - name - level - message`). Supporte la sortie console et fichier simultanÃ©e.

---

## 4. Scripts Principaux

### 4.1 `RunBatchWhisper.py` â€” Transcription Batch

**Script principal du projet.** Lance la transcription massive multi-processus.

**Flux d'exÃ©cution :**

```mermaid
flowchart TD
    A["Chargement config YAML"] --> B["Scan fichiers audio<br/>(FileHandler.lister_fichiers)"]
    B --> C["RÃ©partition Ã©quilibrÃ©e<br/>(glouton_n_listes)"]
    C --> D["DÃ©marrage monitoring<br/>(SystemMonitor + PowerMonitor)"]
    D --> E["Lancement N processus<br/>(multiprocessing.Process)"]
    E --> F["Chaque processus :<br/>1. AffinitÃ© CPU<br/>2. Charger modÃ¨le<br/>3. Transcrire sÃ©quentiellement"]
    F --> G["Collecte mÃ©triques<br/>(MetricsCalculator)"]
    G --> H["GÃ©nÃ©ration rapports QoS<br/>(QoSReporter)"]
    H --> I["Export graphiques PNG +<br/>rapport rÃ©sumÃ©"]
```

**Commande :**
```bash
python scripts/RunBatchWhisper.py --config config/default_config.yaml
```

**Options :**
- `--config` : fichier de configuration YAML
- `--scan-only` : scanner les fichiers sans lancer la transcription

---

### 4.2 `BenchmarkModels.py` â€” Benchmark Comparatif

Ã‰value les performances de chaque modÃ¨le Whisper (tiny â†’ large) sur plusieurs fichiers audio avec N rÃ©pÃ©titions.

**MÃ©triques par test :**
- Temps moyen, mÃ©dian, min, max, Ã©cart-type
- RT factor (Real-Time) : rapport `durÃ©e_audio / temps_traitement`
- Matrice croisÃ©e `durÃ©e Ã— modÃ¨le` exportÃ©e en CSV

**Commande :**
```bash
python scripts/BenchmarkModels.py --config config/benchmark_config.yaml --models tiny base small medium --repetitions 5
```

---

### 4.3 `RunPipeline.py` â€” Pipeline Automatique

Orchestrateur qui enchaÃ®ne toutes les Ã©tapes :

| Ã‰tape | Description |
|---|---|
| 1. Scan | Inventaire des fichiers audio |
| 2. Transcription | Lancement de `RunBatchWhisper` |
| 3. Rapports QoS | GÃ©nÃ©ration des graphiques via `ComputeQoS` |
| 4. Tests | ExÃ©cution des tests unitaires (optionnel) |

---

### 4.4 `CompareTranscriptions.py` â€” Comparaison de QualitÃ©

Compare deux transcriptions (ex: Small vs Medium) et produit :
- **WER relatif** : diffÃ©rence en pourcentage
- **Analyse mot Ã  mot** : substitutions, insertions, suppressions (via `difflib.SequenceMatcher`)
- **Rapport HTML** : visualisation colorÃ©e des diffÃ©rences
- **Rapport texte** : rÃ©sumÃ© avec exemples d'Ã©carts

---

### 4.5 `GenerateExcelReport.py` â€” Rapport Excel

Convertit les rÃ©sultats CSV des benchmarks en fichier Excel formatÃ© avec :
- Feuille de donnÃ©es brutes
- Matrice pivot croisÃ©e (durÃ©e Ã— modÃ¨le)
- Graphiques intÃ©grÃ©s (barres par modÃ¨le, lignes par durÃ©e)

---

### 4.6 `ComputeQoS.py` â€” Post-Traitement QoS

GÃ©nÃ¨re les graphiques de monitoring Ã  partir des CSV produits pendant la transcription. Utile pour rÃ©gÃ©nÃ©rer les graphiques sans relancer la transcription.

```bash
python scripts/ComputeQoS.py --session-dir output/reports
```

---

## 5. Configuration

Le fichier `config/default_config.yaml` centralise toute la configuration du systÃ¨me, organisÃ©e en sections :

| Section | ParamÃ¨tres clÃ©s |
|---|---|
| `hardware` | Nombre de cÅ“urs (24), threads (36), processus max (30), RAM totale (256 Go) |
| `whisper` | ModÃ¨le (`medium`), langue (`fr`), device (`cpu`), `compute_type` (`int8`), affinitÃ© CPU par processus, formats de sortie |
| `preprocessing` | Format WAV, 48 kHz, mono, PCM16, segmentation |
| `qos` | Intervalle monitoring (10s), seuils d'alerte CPU/RAM, monitoring Ã©nergÃ©tique, coÃ»t â‚¬/kWh |
| `export` | Encodage UTF-8, mÃ©tadonnÃ©es JSON, backup automatique |
| `paths` | RÃ©pertoires d'entrÃ©e (BDD audio), sortie, logs, trackers, backup |
| `logging` | Niveau INFO, rotation 100 Mo, 5 backups |
| `batch` | Taille batch (24), retries (3), tri par durÃ©e |

---

## 6. DÃ©pendances

Fichier `requirements.txt` :

| CatÃ©gorie | Packages |
|---|---|
| **IA / Transcription** | `faster-whisper` (CTranslate2) |
| **Audio** | `ffmpeg-python`, `librosa`, `mutagen`, `pydub` |
| **Data** | `numpy`, `pandas` |
| **Monitoring** | `psutil` |
| **Visualisation** | `matplotlib`, `seaborn` |
| **Configuration** | `PyYAML` |
| **Tests** | `pytest`, `pytest-cov` |
| **Utilitaires** | `tqdm`, `python-dateutil` |

---

## 7. Tests

### 7.1 Tests Unitaires (`tests/test_core.py`)

11 tests couvrant les modules principaux :

| Classe de test | Tests | Ce qui est vÃ©rifiÃ© |
|---|---|---|
| `TestModelManager` | 4 | SpÃ©cifications modÃ¨les, suffixes, estimation RAM (int8), validation mÃ©moire |
| `TestCPUAffinityManager` | 3 | Algorithme glouton (basique, Ã©quilibrage, liste vide) |
| `TestMetricsCalculator` | 3 | Throughput, taux de rÃ©ussite, WER (identique + diffÃ©rent) |
| `TestFichierAudio` | 1 | CrÃ©ation d'objet avec extraction de durÃ©e |

**Commande :**
```bash
python3 tests/test_core.py
# ou
python3 -m pytest tests/test_core.py -v
```

---

## 8. Flux de Fonctionnement Global

```mermaid
flowchart LR
    subgraph EntrÃ©e
        A["ğŸ“‚ BDD Audio TNT<br/>720h de MP3"]
    end
    
    subgraph "Station TV"
        B["ğŸ“‹ Scan & Inventaire<br/>(FileHandler)"]
        C["âš–ï¸ RÃ©partition<br/>(Glouton N-listes)"]
        D["ğŸ”„ 30 Processus<br/>parallÃ¨les"]
        E["ğŸ¤ faster-whisper<br/>(CTranslate2 int8)"]
        F["ğŸ“Š Monitoring<br/>(CPU/RAM/IO/Power)"]
    end
    
    subgraph Sortie
        G["ğŸ“„ Transcriptions<br/>TXT + SRT"]
        H["ğŸ“ˆ Rapports QoS<br/>PNG + CSV"]
        I["ğŸ“Š MÃ©triques<br/>Throughput, WER"]
    end
    
    A --> B --> C --> D --> E
    E --> G
    D --> F --> H
    D --> I
```

---

## 9. Performances Attendues

### Configuration actuelle (30 processus, modÃ¨le medium, int8)

| MÃ©trique | Valeur estimÃ©e |
|---|---|
| **RAM totale** | ~20-30 Go (avec faster-whisper int8) |
| **Throughput global** | ~120-150Ã— temps rÃ©el |
| **Temps pour 720h d'audio** | ~5-6 heures |
| **Consommation CPU** | ~83% utilisation moyenne |

### Comparaison avec l'ancienne implÃ©mentation (PyTorch)

| | PyTorch (openai-whisper) | CTranslate2 (faster-whisper) |
|---|---|---|
| **RAM (30 proc.)** | ~100 Go | **~20-30 Go** |
| **Throughput/proc.** | ~2.7Ã— | **~4-5Ã—** |
| **Throughput global** | ~81Ã— | **~120-150Ã—** |
| **Temps total** | ~9 heures | **~5-6 heures** |

---

## 10. Convention de Nommage (STVD-MNER)

Les fichiers de transcription suivent une convention stricte :

```
{YYYYMMDD_HH_MM}_transcript_{suffixe_modÃ¨le}.txt
{YYYYMMDD_HH_MM}_transcript_st_{suffixe_modÃ¨le}.srt
```

**Exemple :**
```
20260216_14_00_transcript_wm.txt      # Texte brut, modÃ¨le medium
20260216_14_00_transcript_st_wm.srt   # Sous-titres, modÃ¨le medium
```

Les suffixes de modÃ¨le sont : `wt` (tiny), `wb` (base), `ws` (small), `wm` (medium), `wl` (large).
